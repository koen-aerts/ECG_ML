{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author\n",
    "[Koen Aerts](https://koenaerts.ca/) @ [Mobia Technology Innovations](https://mobia.io)\n",
    "\n",
    "[myOpenHealth](https://mobia.io/healthcare/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "In this notebook we will use the CSV files created from the \"04_prep_imported_data\" notebook to train, validate and test our model.\n",
    "\n",
    "Many other models that have been published seem to be using a Convolutional Neural Network build on Keras layers. Instead, we will be using Tensorflow's DNNClassifier Estimator, which results in code that is much shorter and easier to read, and leaves all the complexities of building the Neural Network to Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "Load the CSV files with training, validation, and testing data. These files are generated by the \"04_prep_imported_data\" notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Training dataset.\n",
    "df = pd.read_csv(\"train.csv\", header=None)\n",
    "x_train = df.values[:, :-1]\n",
    "y_train = df.values[:, -1].astype(int)\n",
    "\n",
    "# Validation dataset.\n",
    "df = pd.read_csv(\"validate.csv\", header=None)\n",
    "x_validate = df.values[:, :-1]\n",
    "y_validate = df.values[:, -1].astype(int)\n",
    "\n",
    "# Test dataset.\n",
    "df = pd.read_csv(\"test.csv\", header=None)\n",
    "x_test = df.values[:, :-1]\n",
    "y_test = df.values[:, -1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "494fc8a26ba40beb73fc1a4f7b219b213fb7705e"
   },
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "425c4b7abe39a14c6f81f8a71094cc1024276935"
   },
   "source": [
    "# Visualize Data\n",
    "Display one Normal, and one Abnormal heartbeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bcd502ecd1eb95bbf8af983396d3d0c3fb50ce4b"
   },
   "outputs": [],
   "source": [
    "C0 = np.argwhere(y_train == 0).flatten()\n",
    "C1 = np.argwhere(y_train == 1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "85209065f110cea77f4d65053d1164e9ee816049"
   },
   "outputs": [],
   "source": [
    "x = np.arange(0, 187)*8/1000.0\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.plot(x, x_train[C0, :][0], label=\"Normal\") # Display first normal beat.\n",
    "plt.plot(x, x_train[C1, :][0], label=\"Abnormal\") # Display first abnormal beat.\n",
    "plt.legend()\n",
    "plt.title(\"1-beat ECG for every category\", fontsize=20)\n",
    "plt.ylabel(\"Normalized Amplitude (0 - 1)\", fontsize=15)\n",
    "plt.xlabel(\"Time (ms)\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c4de23b85abe34a726eab268171da0e827bafa35"
   },
   "source": [
    "# Train Model\n",
    "Use the Tensorflow Estimator API to build out the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column('beat', shape=[187])]\n",
    "\n",
    "estimator = tf.estimator.DNNClassifier(\n",
    "   feature_columns=feature_columns,\n",
    "   hidden_units=[256, 64, 16],\n",
    "   optimizer=tf.train.AdamOptimizer(1e-4),\n",
    "   n_classes=2,\n",
    "   dropout=0.1,\n",
    "   model_dir='ecg_model'\n",
    ")\n",
    "\n",
    "input_fn_train = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'beat': x_train},\n",
    "    y=y_train,\n",
    "    num_epochs=None,\n",
    "    batch_size=50,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.train(input_fn=input_fn_train, steps=400000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Model\n",
    "Evaluate how well the model is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn_validate = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'beat': x_validate},\n",
    "    y=y_validate,\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = estimator.evaluate(input_fn=input_fn_validate)\n",
    "print('\\nTest Accuracy: {0:f}%\\n'.format(accuracy_score['accuracy']*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model\n",
    "Testing the model by doing predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn_test = tf.estimator.inputs.numpy_input_fn(\n",
    " x={'beat': x_test},\n",
    " y=y_test,\n",
    " num_epochs=1,\n",
    " shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = estimator.predict(input_fn=input_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totvals = 0\n",
    "totwrong = 0\n",
    "\n",
    "for prediction, expected in zip(predictions, y_test):\n",
    "    totvals = totvals + 1\n",
    "    catpred = prediction['class_ids'][0]\n",
    "    certainty = prediction['probabilities'][catpred] * 100\n",
    "    if (expected != catpred):\n",
    "        totwrong = totwrong + 1\n",
    "        #print (prediction)\n",
    "        print('Real: ', expected, ', pred: ', catpred, ', cert: ', certainty)\n",
    "\n",
    "print('Accuracy: ', ((totvals - totwrong) * 100.0 / totvals))\n",
    "print('Wrong: ', totwrong, ' out of ', totvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring\n",
    "Use TensorBoard in a separate tab in your browser to analyze your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitoring with TensorBoard\n",
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('ecg_model')\n",
    "TensorBoard().list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop TensorBoard\n",
    "for pid in TensorBoard.list()['pid']:\n",
    "    TensorBoard().stop(pid)\n",
    "    print('Stopped TensorBoard with pid ', pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Model\n",
    "Exporting the model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build receiver function, and export.\n",
    "#feature_spec = tf.feature_column.make_parse_example_spec(feature_columns)\n",
    "#serving_input_receiver_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\n",
    "feature_placeholders = { 'beat': tf.placeholder(dtype=tf.float32, shape=(187,)) }\n",
    "serving_input_receiver_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(feature_placeholders)\n",
    "export_dir = estimator.export_savedmodel('ecg_serving', serving_input_receiver_fn, strip_default_attrs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
